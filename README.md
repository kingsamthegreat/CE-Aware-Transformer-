# CE-Aware-Transformer

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kingsamthegreat/CE-Aware-Transformer-/blob/main/notebooks/demo.ipynb)
Prototype implementation of a Transformer informed by the Consciousness Equation (CE = I × A × Θ).

## Overview
The CE-Aware Transformer integrates observer-field tensors with standard attention mechanisms.
It is designed to simulate and compare CE dynamics with Integrated Information Theory (IIT)
across neural and AI systems.

## Objectives
- Build initial notebooks for testing CE-based transformations on synthetic data.
- Simulate observer-field interactions using small transformer blocks.
- Compare outputs with Integrated Information Theory (IIT) baselines.
- Document results for future expansion into full-scale models.

## Quick Start (local)
1. Create a Python virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate   # macOS/Linux
   venv\Scripts\activate    # Windows PowerShell
   ```
2. Install requirements:
   ```bash
   pip install -r requirements.txt
   ```
3. Run the demo script (or open the notebook):
   ```bash
   python run_demo.py
   # or open notebooks/demo.ipynb in Jupyter
   ```

## Project layout
```
CE-Aware-Transformer/
 ├── notebooks/
 │    └── demo.ipynb
 ├── src/
 │    └── ce_layer.py
 ├── README.md
 ├── LICENSE
 ├── .gitignore
 └── requirements.txt
```

## Contact
Obasi Ikechukwu Samuel — thegreatertoe@gmail.com

## License
This project is released under the MIT License. See the LICENSE file for details.
